---
title: "Final Project"
author: "Sara Culhane and Brenna Sullivan"
date: "December 22, 2017"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
    df_print: kable
---




## Load all packages

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
require(mosaic)   # Load additional packages here 
library(ggplot2)

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```



## Load data and perform data cleaning

Please delete all "notes" before submission.

Note: CSV/data files should be read assuming they are in the `data` folder. In
other words, load data via `read_csv("data/CSV_NAME.csv")` and not via
`read_csv("/Users/aykim/Documents/MATH495/Final_Project/data/CSV_NAME.csv")`

Kaggle Competition: House Prices: Advanced Regression Techniques (Scoring Mechinism: RMSE)
https://www.kaggle.com/c/house-prices-advanced-regression-techniques

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
train1 <- read.csv("data/FinalProjectTrain.csv", sep=",", stringsAsFactors = F)
train_id <- sample(1:dim(train1)[1], dim(train1)[1]/2, replace = FALSE)
train <- train1[train_id, ] #data to fit the model to
test <- train1[-train_id, ] #data to CV on

kaggle_test <- read.csv("data/FinalProjectTest.csv") #predict SalePrice for kaggle submission

train$logSalePrice <- log(train$SalePrice)
```


```{r}
#Drop factor variables with less than 2 levels & keep non-factor vars
names(train) <- make.names(names(train))

features <- setdiff(colnames(train), c("Id", "SalePrice"))
for (f in features) {
  if (any(is.na(train[[f]]))) 
    if (is.character(train[[f]])){ 
      train[[f]][is.na(train[[f]])] <- "Others"
    }else{
      train[[f]][is.na(train[[f]])] <- -999  
    }
}

column_class <- lapply(train,class)
column_class <- column_class[column_class != "factor"]
factor_levels <- lapply(train, nlevels)
factor_levels <- factor_levels[factor_levels > 1]
train <- train[,names(train) %in% c(names(factor_levels), names(column_class))]

train <- as.data.frame(unclass(train))

#Train model
lmfull <- lm(SalePrice ~ . , data=train)
summary(lmfull)
```

## EDA visualizations and tables

Note: If you had to illustrate using no modelling but only graphs and tables which
variables have the most predictive power, which would you include?

* Perform a cross-validation on only the final/ultimate model used for your
submission.
* The "score" in question should be the same as used to compute the Kaggle
leaderboard. In other words, your estimated score should be roughly equal to the
score returned by Kaggle after your submission.

Predicting Sale Price (in USD) of houses with no modeling:

```{r}
histogram(train$SalePrice, type = "percent", xlab= "Sale Price (USD)", ylab= "Percent of Homes") #skewed right, not normal
bwplot(train$SalePrice, xlab= "Sale Price (USD)")
histogram(train$logSalePrice, type = "percent", xlab = "Log of Sale Price (USD)", ylab = "Percent of Homes") #much more normal when logSalePrice is used
bwplot(train$logSalePrice, xlab = "Log of Sale Price (USD)")
mean(train$SalePrice)
mean(train$logSalePrice)
```

Predicting Sale Price (in USD) of houses with modeling:

```{r}
#Model Formula with all 79 predictor variables
model_formula <- as.formula("logSalePrice ~ MSSubClass + MSZoning + LotFrontage + LotArea + Street + Alley + LotShape + LandContour + Utilities + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2 + BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt + YearRemodAdd + RoofStyle + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtQual + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + X1stFlrSF + X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath  + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + GarageCond + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + PoolQC + Fence + MiscFeature + MiscVal + MoSold + YrSold + SaleType + SaleCondition")
```

###1. Subset Selection (Forward or Backwards selection of predictors (Stat230))
```{r}
lmempty <- lm(logSalePrice ~ 1, data=train) # model with only intercept

step(lmempty, scope=list(lower=lmempty, upper=lmfull), direction="forward")
```


###2. Dimension Reduction (PCA)


###3. Shrinkage/ Regularization (LASSO)



## Crossvalidation of ultimate model

Note: Hardcode your crossvalidation here i.e. do not use built-in crossvalidation
options.

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}

```



## Create submission

Note: Output a CSV using `write_csv(DATAFRAME_NAME, path="data/SUBMISSION_NAME.csv")`
that is Kaggle submitable. This submission should return a Kaggle score that is
close to your crossvalidated score.



## Citations and references

Note: All citations and references must be included here.



## Supplementary materials

Note: Anything else you've tried that you'd like to include, but isn't essential to
the above, like other EDA's, other modeling approaches you've tried, etc. Please
set the R code chunk `eval=FALSE` here so that default is that R Markdown
doesn't run the code, but a user can flip this switch if they are curious.

```{r, eval=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}


```





