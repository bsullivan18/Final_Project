---
title: "Final Project"
author: "Sara Culhane and Brenna Sullivan"
date: "December 22, 2017"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
    df_print: kable
---




## Load all packages

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
require(mosaic)   # Load additional packages here 
library(ggplot2)

# Some customization.  You can alter or delete as desired (if you know what you are doing).
trellis.par.set(theme=theme.mosaic()) # change default color scheme for lattice
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```



## Load data and perform data cleaning

Please delete all "notes" before submission.

Note: CSV/data files should be read assuming they are in the `data` folder. In
other words, load data via `read_csv("data/CSV_NAME.csv")` and not via
`read_csv("/Users/aykim/Documents/MATH495/Final_Project/data/CSV_NAME.csv")`

Kaggle Competition: House Prices: Advanced Regression Techniques (Scoring Mechinism: RMSE)
https://www.kaggle.com/c/house-prices-advanced-regression-techniques

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
set.seed(1)
train1 <- read.csv("data/FinalProjectTrain.csv", sep=",", stringsAsFactors = F)
train_id <- sample(1:dim(train1)[1], 3*dim(train1)[1]/4, replace = FALSE)
train <- train1[train_id, ] #data to fit the model to
test <- train1[-train_id, ] #data to CV on

kaggle_test <- read.csv("data/FinalProjectTest.csv") #predict SalePrice for kaggle submission
```


```{r}
#Drop factor variables with less than 2 levels & keep non-factor vars from Kaggle Competition discusstion(https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/24399)

names(train) <- make.names(names(train))

features <- setdiff(colnames(train), c("Id", "SalePrice"))
for (f in features) {
  if (any(is.na(train[[f]]))) 
    if (is.character(train[[f]])){ 
      train[[f]][is.na(train[[f]])] <- "Others"
    }else{
      train[[f]][is.na(train[[f]])] <- -999  
    }
}

column_class <- lapply(train,class)
column_class <- column_class[column_class != "factor"]
factor_levels <- lapply(train, nlevels)
factor_levels <- factor_levels[factor_levels > 1]
train <- train[,names(train) %in% c(names(factor_levels), names(column_class))]
test <- train[,names(train) %in% c(names(factor_levels), names(column_class))]
train <- as.data.frame(unclass(train))
train <- as.data.frame(unclass(test))
```

## EDA visualizations and tables

Note: If you had to illustrate using no modelling but only graphs and tables which
variables have the most predictive power, which would you include?

* Perform a cross-validation on only the final/ultimate model used for your
submission.
* The "score" in question should be the same as used to compute the Kaggle
leaderboard. In other words, your estimated score should be roughly equal to the
score returned by Kaggle after your submission.

Predicting Sale Price (in USD) of houses with no modeling:

```{r}
histogram(train$SalePrice, type = "percent", xlab= "Sale Price (USD)", ylab= "Percent of Homes") #skewed right, not normal
bwplot(train$SalePrice, xlab= "Sale Price (USD)")
histogram(log(train$SalePrice), type = "percent", xlab = "Log of Sale Price (USD)", ylab = "Percent of Homes") #much more normal when logSalePrice is used
bwplot(log(train$SalePrice), xlab = "Log of Sale Price (USD)")
mean(train$SalePrice)
mean(log(train$SalePrice))
```

Predicting Sale Price (in USD) of houses with modeling:

###1. Subset Selection (Forward or Backwards selection of predictors (Stat230))

```{r}
train$log_saleprice <- log(train$SalePrice)

model_formula <- as.formula("log_saleprice ~ Id + MSSubClass + MSZoning + LotFrontage + LotArea + Street + Alley + LotShape + LandContour + LotConfig + LandSlope + Neighborhood + Condition1 + Condition2+ BldgType + HouseStyle + OverallQual + OverallCond + YearBuilt +YearRemodAdd + RoofStyle + RoofMatl + Exterior1st + Exterior2nd + MasVnrType + MasVnrArea + ExterQual + ExterCond + Foundation + BsmtCond + BsmtExposure + BsmtFinType1 + BsmtFinSF1 + BsmtFinType2 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + Heating + HeatingQC + CentralAir + Electrical + X1stFlrSF + X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath +BsmtHalfBath + FullBath + HalfBath + BedroomAbvGr + KitchenAbvGr + KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + FireplaceQu + GarageType + GarageYrBlt + GarageFinish + GarageCars + GarageArea + GarageQual + PavedDrive + WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + PoolQC + Fence + MiscFeature + MiscVal + MoSold + YrSold + SaleType + SaleCondition")
```


```{r}
lmfull <- lm(model_formula, data=train)

lmempty <- lm(log_saleprice ~ 1, data=train) # model with only intercept
```

```{r}
model1 <- step(lmempty, scope=list(lower=lmempty, upper=lmfull), direction="forward")
summary(model1)
test$log_saleprice <- log(test$SalePrice)
preds <- predict(model1,test)

diffs <- preds - test$log_saleprice
RMSE <- function(diffs) {
  RMSE <- sqrt(mean((diffs)^2))
  return(RMSE)
}
RMSE(diffs)
```


###2. Dimension Reduction (PCA)

### PCA using top quantative 

```{r}
library(factoextra)
pca <- train %>% 
  select(log_saleprice,GrLivArea,GarageArea,LotFrontage, OverallQual,OverallCond,BsmtFinSF1,BsmtFinSF2,TotalBsmtSF,TotRmsAbvGrd,PoolArea,YearBuilt,YearRemodAdd)
pca_comp <- prcomp(pca,scale=FALSE)
fviz_eig(pca_comp)

fviz_pca_ind(pca_comp,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

fviz_pca_var(pca_comp,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )
```

```{r}
X <- train %>% 
  select(TotalBsmtSF,LotFrontage,YearBuilt)
ggplot(data=X, aes(x=TotalBsmtSF, y=LotFrontage)) +
  geom_text(label=X$YearBuilt) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", size=0.5, col="black") +
  labs(x="X1: TotalBsmtSF", y="X2: LotFrontage")
```

###3. Shrinkage/ Regularization (LASSO)
```{r}
library(glmnet)
library(tidyr)
get_LASSO_coefficients <- function(LASSO_fit){
  coeff_values <- LASSO_fit %>% 
    broom::tidy() %>% 
    as_tibble() %>% 
    select(-c(step, dev.ratio)) %>% 
    tidyr::complete(lambda, nesting(term), fill = list(estimate = 0)) %>% 
    arrange(desc(lambda)) %>% 
    select(term, estimate, lambda)
  return(coeff_values)
}

predictor_matrix <- model.matrix(model_formula, data=train)[, -1]
lambda_inputs <- 10^seq(-2, 10, length = 100)

LASSO_fit <- glmnet(x=predictor_matrix, y=train$log_saleprice, alpha = 1, lambda = lambda_inputs)

# 5. Get beta-hat coefficients for ALL values of knob/tuning parameter lambda
LASSO_coefficients <- get_LASSO_coefficients(LASSO_fit)

ggplot(LASSO_coefficients, aes(x=lambda, y=estimate, col=term)) +
  geom_line() +
  labs(x="lambda", y="beta-hat coefficient estimate")
```

```{r}
plot_LASSO_coefficients <- LASSO_coefficients %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x=lambda, y=estimate, col=term)) +
  geom_line() +
  scale_x_log10() +
  labs(x="lambda (log10-scale)", y="beta-hat coefficient estimate",
       title="LASSO regularized coefficient for each lambda value")
plot_LASSO_coefficients
```

```{r}
plot_LASSO_coefficients +
  coord_cartesian(xlim= c(.01, .6), ylim=c(-.0001, .0001))
```

```{r}
LASSO_CV <- cv.glmnet(x=predictor_matrix, y=log(train$SalePrice), alpha=1, lambda=lambda_inputs)
lambda_star <- LASSO_CV$lambda.min
lambda_star_1SE <- LASSO_CV$lambda.1se

#code for finding the variables that should be used when lambda=1SE (from stack exchange)
c <- coef(LASSO_CV, s= lambda_star_1SE, exact=TRUE)
inds <- which(c!=0)
variables <- row.names(c)[inds]
variables
```



## Crossvalidation of ultimate model

Note: Hardcode your crossvalidation here i.e. do not use built-in crossvalidation
options.

```{r}
LASSO_CV <- cv.glmnet(x=predictor_matrix, y=train$log_saleprice, alpha=1, lambda=lambda_inputs)

# Optimal lambdas
lambda_star <- LASSO_CV$lambda.min
lambda_star_1SE <- LASSO_CV$lambda.1se

```

```{r}
plot(LASSO_CV)
abline(v=log(lambda_star), col="red")
abline(v=log(lambda_star_1SE), col="blue")

plot_LASSO_coefficients <- plot_LASSO_coefficients +
  geom_vline(xintercept = lambda_star, col="red", alpha=0.4, linetype="dashed") +
  geom_vline(xintercept = lambda_star_1SE, col="blue", alpha=0.4, linetype="dashed")
plot_LASSO_coefficients
plot_LASSO_coefficients +
  coord_cartesian(xlim=c(1, 1000), ylim=c(-1, 1))
y_hat <- predict(LASSO_fit, newx=predictor_matrix, s=lambda_star_1SE) %>% 
  as.vector()
hist(y_hat)
```





## Create submission

Note: Output a CSV using `write_csv(DATAFRAME_NAME, path="data/SUBMISSION_NAME.csv")`
that is Kaggle submitable. This submission should return a Kaggle score that is
close to your crossvalidated score.



## Citations and references

Note: All citations and references must be included here.



## Supplementary materials

Note: Anything else you've tried that you'd like to include, but isn't essential to
the above, like other EDA's, other modeling approaches you've tried, etc. Please
set the R code chunk `eval=FALSE` here so that default is that R Markdown
doesn't run the code, but a user can flip this switch if they are curious.

```{r, eval=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}


```




